{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get request to main page and getting and parsing to `BeautifulSoup` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://zeenews.india.com'\n",
    "\n",
    "request = requests.get(url)\n",
    "\n",
    "text = request.text\n",
    "\n",
    "z_html = BeautifulSoup(text,\"html.parser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to convert unicode into string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(to_convert):\n",
    "    return [i.encode('ascii','ignore') for i in to_convert]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Names of all the states or regions from html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andhra Pradesh',\n",
       " 'Assam',\n",
       " 'Bihar',\n",
       " 'Chhattisgarh',\n",
       " 'Delhi NCR',\n",
       " 'Goa',\n",
       " 'Gujarat',\n",
       " 'Haryana',\n",
       " 'Himachal Pradesh',\n",
       " 'Jammu and Kashmir',\n",
       " 'Jharkhand',\n",
       " 'Karnataka',\n",
       " 'Kerala',\n",
       " 'Madhya Pradesh',\n",
       " 'Maharashtra',\n",
       " 'North East',\n",
       " 'Odisha',\n",
       " 'Punjab',\n",
       " 'Rajasthan',\n",
       " 'Tamil Nadu',\n",
       " 'Telangana',\n",
       " 'Uttar Pradesh',\n",
       " 'Uttarakhand',\n",
       " 'UTs',\n",
       " 'West Bengal']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = z_html.find_all(\"span\")\n",
    "\n",
    "states_ht = span[7:32]\n",
    "\n",
    "states = [state.get_text() for state in states_ht]\n",
    "\n",
    "states = convert(states)\n",
    "\n",
    "states = [i.strip() for i in states]\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiating a loop for every state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andhra Pradesh\n",
      "http://zeenews.india.com//state/Andhra-Pradesh?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Andhra-Pradesh?page=1\n",
      "Page Scraped\n",
      "Assam\n",
      "http://zeenews.india.com//state/Assam?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Assam?page=1\n",
      "Page Scraped\n",
      "Bihar\n",
      "http://zeenews.india.com//state/Bihar?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Bihar?page=1\n",
      "Page Scraped\n",
      "Chhattisgarh\n",
      "http://zeenews.india.com//state/Chhattisgarh?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Chhattisgarh?page=1\n",
      "Page Scraped\n",
      "Delhi NCR\n",
      "http://zeenews.india.com//state/delhi?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/delhi?page=1\n",
      "Page Scraped\n",
      "Goa\n",
      "http://zeenews.india.com//state/Goa?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Goa?page=1\n",
      "Page Scraped\n",
      "Gujarat\n",
      "http://zeenews.india.com//state/Gujarat?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Gujarat?page=1\n",
      "Page Scraped\n",
      "Haryana\n",
      "http://zeenews.india.com//state/Haryana?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Haryana?page=1\n",
      "Page Scraped\n",
      "Himachal Pradesh\n",
      "http://zeenews.india.com//state/Himachal-Pradesh?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Himachal-Pradesh?page=1\n",
      "Page Scraped\n",
      "Jammu and Kashmir\n",
      "http://zeenews.india.com//state/Jammu-and-Kashmir?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Jammu-and-Kashmir?page=1\n",
      "Page Scraped\n",
      "Jharkhand\n",
      "http://zeenews.india.com//state/Jharkhand?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Jharkhand?page=1\n",
      "Page Scraped\n",
      "Karnataka\n",
      "http://zeenews.india.com//state/Karnataka?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Karnataka?page=1\n",
      "Page Scraped\n",
      "Kerala\n",
      "http://zeenews.india.com//state/Kerala?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Kerala?page=1\n",
      "Page Scraped\n",
      "Madhya Pradesh\n",
      "http://zeenews.india.com//state/Madhya-Pradesh?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Madhya-Pradesh?page=1\n",
      "Page Scraped\n",
      "Maharashtra\n",
      "http://zeenews.india.com//state/Maharashtra?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Maharashtra?page=1\n",
      "Page Scraped\n",
      "North East\n",
      "http://zeenews.india.com//state/North-East?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/North-East?page=1\n",
      "Page Scraped\n",
      "Odisha\n",
      "http://zeenews.india.com//state/Odisha?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Odisha?page=1\n",
      "Page Scraped\n",
      "Punjab\n",
      "http://zeenews.india.com//state/Punjab?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Punjab?page=1\n",
      "Page Scraped\n",
      "Rajasthan\n",
      "http://zeenews.india.com//state/Rajasthan?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Rajasthan?page=1\n",
      "Page Scraped\n",
      "Tamil Nadu\n",
      "http://zeenews.india.com//state/Tamil-Nadu?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Tamil-Nadu?page=1\n",
      "Page Scraped\n",
      "Telangana\n",
      "http://zeenews.india.com//state/Telangana?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Telangana?page=1\n",
      "Page Scraped\n",
      "Uttar Pradesh\n",
      "http://zeenews.india.com//state/Uttar-Pradesh?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Uttar-Pradesh?page=1\n",
      "Page Scraped\n",
      "Uttarakhand\n",
      "http://zeenews.india.com//state/Uttarakhand?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/Uttarakhand?page=1\n",
      "Page Scraped\n",
      "UTs\n",
      "http://zeenews.india.com//state/UTs?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/UTs?page=1\n",
      "Page Scraped\n",
      "West Bengal\n",
      "http://zeenews.india.com//state/West-Bengal?page=0\n",
      "Page Scraped\n",
      "http://zeenews.india.com//state/West-Bengal?page=1\n",
      "Page Scraped\n"
     ]
    }
   ],
   "source": [
    "date = []\n",
    "\n",
    "concerned_state = []\n",
    "\n",
    "title = []\n",
    "\n",
    "content = []\n",
    "\n",
    "for state in states:\n",
    "    if state == \"Delhi NCR\":\n",
    "        st_url = url + \"/state/\" + \"delhi\"\n",
    "    else:\n",
    "        st_url = url + \"/state/\" + state.strip().replace (\" \", \"-\")\n",
    "    #print st_url ##Got the url for each state\n",
    "    print state\n",
    "    ##Looping through the number of pages for the website for a particular state\n",
    "    for i in range(2):\n",
    "        page = st_url + \"?page=\" + str(i)\n",
    "        ##Get request to each page\n",
    "        print page\n",
    "        request = requests.get(page)\n",
    "        txt = request.text\n",
    "        page_html = BeautifulSoup(txt,\"html.parser\") ## Created BeautifulSoup object for the page\n",
    "        \n",
    "        ##Getting the title for each article\n",
    "        page_span = page_html.find_all(\"span\")\n",
    "        \n",
    "        title_html = [i.find_all(\"a\") for i in page_span if i.get(\"class\")==[\"lead-health-ab\"]]\n",
    "        \n",
    "        flat = [x for sub in title_html for x in sub]\n",
    "        \n",
    "        title_inc = [i.get_text() for i in flat ]\n",
    "\n",
    "        title.append(convert(title_inc))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        ##Getting the date for each article\n",
    "        hyperlink_inc = [i[\"href\"] for i in flat]\n",
    "\n",
    "        hyperlink = convert(hyperlink_inc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(len(hyperlink)):\n",
    "        \n",
    "            link = \"http://zeenews.india.com\" + hyperlink[0]\n",
    "            \n",
    "            if i==29:\n",
    "                print \"Page Scraped\"\n",
    "            \n",
    "            req1 = requests.get(link)\n",
    "            \n",
    "            concerned_state.append(state)\n",
    "\n",
    "            txt = req1.text\n",
    "\n",
    "            blog1 = BeautifulSoup(txt,\"html.parser\")\n",
    "\n",
    "            div = [i for i in blog1.find_all(\"div\") if i.get(\"class\")]\n",
    "\n",
    "            div1 = blog1.find_all(\"div\")\n",
    "\n",
    "            div2 = [i for i in div1 if i.get(\"class\")]\n",
    "\n",
    "            date_html = []\n",
    "            for i in div1:\n",
    "                if i.get(\"class\"):\n",
    "                    for j in i.get(\"class\"):\n",
    "                        if j==\"writer\":\n",
    "                            date_html.append(i)\n",
    "                            \n",
    "          \n",
    "            date1 = date_html[0].get_text().strip()\n",
    "            date.append(date1.split(\",\")[1] + date1.split(\",\")[2].split(\"-\")[0])\n",
    "\n",
    "        ## Getting the content of the articles\n",
    "        page_p = page_html.find_all(\"p\")\n",
    "        content_inc = [i.get_text() for i in page_p if i.a == None]\n",
    "        content.append(convert(content_inc))\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "st_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1500\n",
      "1500\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flat_content = [x for sub in content for x in sub]\n",
    "\n",
    "content_new = [i for i in flat_content]\n",
    "\n",
    "flat_title = [x for sub in title for x in sub]\n",
    "\n",
    "title_new = [i for i in flat_title]\n",
    "\n",
    "#rows = [(dat,tit,con,st) for dat in date for tit in title_new for con in content_new for st in state]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame(columns=[\"Date\",\"Title\",\"Content\",\"State\"])\n",
    "\n",
    "data[\"Date\"] = date\n",
    "\n",
    "data[\"Title\"] = title_new\n",
    "\n",
    "data[\"Content\"] = content_new\n",
    "\n",
    "\n",
    "\n",
    "print len(title_new)\n",
    "print len(content_new)\n",
    "print len(concerned_state)\n",
    "print len(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[\"State\"] = concerned_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>October 9 2015</td>\n",
       "      <td>No trace of TDP leaders abducted by Maoists</td>\n",
       "      <td>Police sources today said the Maoists may have...</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 9 2015</td>\n",
       "      <td>Kidnapped Hyderabad engineer rescued in Meghalaya</td>\n",
       "      <td>A kidnapped engineer of a Hyderabad-based roa...</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 9 2015</td>\n",
       "      <td>Still no clue about abducted TDP leaders' wher...</td>\n",
       "      <td>Police till late tonight failed to find any c...</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>October 9 2015</td>\n",
       "      <td>Andhra Pradesh: Search on for TDP leaders abdu...</td>\n",
       "      <td>State police are still ascertaining the locati...</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October 9 2015</td>\n",
       "      <td>Police arrests seven-member gang who cheated a...</td>\n",
       "      <td>The police arrested a seven-member gang which...</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                              Title  \\\n",
       "0   October 9 2015         No trace of TDP leaders abducted by Maoists   \n",
       "1   October 9 2015   Kidnapped Hyderabad engineer rescued in Meghalaya   \n",
       "2   October 9 2015   Still no clue about abducted TDP leaders' wher...   \n",
       "3   October 9 2015   Andhra Pradesh: Search on for TDP leaders abdu...   \n",
       "4   October 9 2015   Police arrests seven-member gang who cheated a...   \n",
       "\n",
       "                                             Content           State  \n",
       "0  Police sources today said the Maoists may have...  Andhra Pradesh  \n",
       "1   A kidnapped engineer of a Hyderabad-based roa...  Andhra Pradesh  \n",
       "2   Police till late tonight failed to find any c...  Andhra Pradesh  \n",
       "3  State police are still ascertaining the locati...  Andhra Pradesh  \n",
       "4   The police arrested a seven-member gang which...  Andhra Pradesh  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_excel('zeenewsdata.xlsx',encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
